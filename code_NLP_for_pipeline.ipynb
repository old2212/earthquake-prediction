{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import EvalPrediction\n",
    "import transformers\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import PreTrainedTokenizerFast"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Ignore', 'Machine_alert', 'Human_alert', 'Damages_alert']\n",
    "id2label = {0: 'Ignore', 1: 'Machine_alert', 2: 'Human_alert', 3: 'Damages_alert'}\n",
    "label2id = {'Ignore': 0, 'Machine_alert': 1, 'Human_alert': 2, 'Damages_alert': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at vinai3/bertweet-large/checkpoint-130 were not used when initializing BertForSequenceClassification: ['roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.19.output.LayerNorm.weight', 'roberta.encoder.layer.20.attention.self.value.bias', 'roberta.encoder.layer.22.attention.self.query.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.12.output.LayerNorm.weight', 'roberta.encoder.layer.23.intermediate.dense.weight', 'roberta.encoder.layer.18.attention.output.LayerNorm.weight', 'roberta.encoder.layer.23.attention.self.key.bias', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.19.output.dense.weight', 'roberta.encoder.layer.14.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.19.attention.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.self.value.bias', 'roberta.encoder.layer.1.attention.self.query.weight', 'classifier.dense.weight', 'roberta.encoder.layer.22.attention.self.key.bias', 'roberta.encoder.layer.22.attention.output.dense.weight', 'roberta.encoder.layer.14.attention.output.LayerNorm.weight', 'roberta.encoder.layer.15.attention.self.value.weight', 'roberta.encoder.layer.17.attention.output.dense.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.21.attention.self.query.bias', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.17.attention.output.dense.weight', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.17.attention.self.key.bias', 'roberta.encoder.layer.14.attention.self.key.weight', 'roberta.encoder.layer.16.attention.self.value.weight', 'roberta.encoder.layer.15.attention.output.LayerNorm.weight', 'roberta.encoder.layer.17.output.LayerNorm.weight', 'roberta.encoder.layer.19.attention.self.key.weight', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.13.attention.self.value.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.14.attention.self.value.bias', 'roberta.encoder.layer.19.attention.self.value.weight', 'roberta.encoder.layer.16.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.15.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.18.intermediate.dense.bias', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.23.attention.output.dense.weight', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.14.attention.output.dense.weight', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.18.attention.output.dense.weight', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.12.attention.output.dense.bias', 'roberta.encoder.layer.15.output.dense.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.21.attention.output.LayerNorm.bias', 'roberta.encoder.layer.16.attention.self.value.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.14.output.LayerNorm.weight', 'roberta.encoder.layer.16.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.22.attention.output.dense.bias', 'roberta.encoder.layer.23.attention.output.LayerNorm.bias', 'roberta.encoder.layer.18.attention.self.query.weight', 'roberta.encoder.layer.23.attention.self.query.weight', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.18.intermediate.dense.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.23.attention.output.dense.bias', 'roberta.encoder.layer.14.output.dense.weight', 'roberta.encoder.layer.13.attention.output.LayerNorm.weight', 'roberta.encoder.layer.20.attention.self.value.weight', 'roberta.encoder.layer.22.attention.self.value.weight', 'roberta.encoder.layer.16.attention.self.query.weight', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.20.attention.self.key.bias', 'roberta.encoder.layer.13.output.dense.weight', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.12.attention.self.value.weight', 'roberta.encoder.layer.14.attention.output.dense.bias', 'classifier.out_proj.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.12.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.15.attention.output.dense.bias', 'roberta.encoder.layer.18.attention.output.dense.bias', 'roberta.encoder.layer.18.attention.self.key.weight', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.16.intermediate.dense.bias', 'roberta.encoder.layer.15.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.15.attention.self.key.bias', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.15.attention.self.value.bias', 'roberta.encoder.layer.21.attention.self.value.weight', 'classifier.dense.bias', 'roberta.encoder.layer.16.attention.self.query.bias', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.23.output.dense.bias', 'roberta.encoder.layer.19.intermediate.dense.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.13.attention.self.value.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.21.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.23.intermediate.dense.bias', 'roberta.encoder.layer.16.attention.output.dense.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.19.attention.self.key.bias', 'roberta.encoder.layer.20.output.dense.bias', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.12.attention.self.value.bias', 'roberta.encoder.layer.22.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.20.attention.output.dense.weight', 'roberta.encoder.layer.16.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.20.attention.self.key.weight', 'roberta.encoder.layer.17.attention.output.LayerNorm.bias', 'roberta.encoder.layer.16.attention.self.key.bias', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.13.attention.output.dense.bias', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.17.attention.self.key.weight', 'roberta.encoder.layer.12.attention.output.LayerNorm.weight', 'roberta.encoder.layer.18.attention.self.value.weight', 'roberta.encoder.layer.13.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.23.attention.self.key.weight', 'roberta.encoder.layer.21.attention.output.dense.bias', 'roberta.encoder.layer.12.attention.self.key.bias', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.12.intermediate.dense.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.13.attention.self.key.bias', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.22.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.12.attention.output.dense.weight', 'roberta.encoder.layer.13.attention.output.dense.weight', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.23.attention.self.value.weight', 'roberta.encoder.layer.16.output.dense.bias', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.20.attention.self.query.bias', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.12.intermediate.dense.weight', 'roberta.encoder.layer.17.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.19.output.LayerNorm.bias', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.20.output.dense.weight', 'roberta.encoder.layer.22.attention.self.value.bias', 'roberta.encoder.layer.21.output.LayerNorm.weight', 'roberta.encoder.layer.13.output.LayerNorm.bias', 'roberta.encoder.layer.15.attention.self.key.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.20.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.12.output.dense.weight', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.16.output.dense.weight', 'roberta.encoder.layer.15.attention.self.query.bias', 'roberta.encoder.layer.19.attention.self.query.bias', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.22.output.dense.bias', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.15.output.dense.bias', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.17.intermediate.dense.weight', 'roberta.encoder.layer.15.attention.self.query.weight', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.19.output.dense.bias', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.19.intermediate.dense.weight', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.13.intermediate.dense.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.18.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.20.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.21.output.dense.weight', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.23.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.20.output.LayerNorm.weight', 'roberta.encoder.layer.17.output.dense.weight', 'roberta.encoder.layer.23.attention.self.query.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.18.attention.output.LayerNorm.bias', 'roberta.encoder.layer.16.output.LayerNorm.bias', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.13.output.dense.bias', 'roberta.encoder.layer.15.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.19.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.16.attention.self.key.weight', 'roberta.encoder.layer.20.attention.self.query.weight', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.13.output.LayerNorm.weight', 'roberta.encoder.layer.14.output.LayerNorm.bias', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.21.attention.self.value.bias', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.15.output.LayerNorm.bias', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.21.attention.self.key.bias', 'roberta.encoder.layer.21.output.dense.bias', 'roberta.encoder.layer.18.attention.self.key.bias', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.14.attention.self.query.bias', 'roberta.encoder.layer.17.attention.self.query.bias', 'roberta.encoder.layer.21.intermediate.dense.bias', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.22.output.dense.weight', 'roberta.encoder.layer.22.intermediate.dense.weight', 'roberta.encoder.layer.13.attention.self.query.bias', 'roberta.encoder.layer.17.attention.self.value.weight', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.20.output.LayerNorm.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.23.output.dense.weight', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.22.intermediate.dense.bias', 'roberta.encoder.layer.14.intermediate.dense.bias', 'roberta.encoder.layer.13.attention.self.key.weight', 'roberta.encoder.layer.14.attention.self.query.weight', 'classifier.out_proj.bias', 'roberta.encoder.layer.12.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.embeddings.position_ids', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.18.attention.self.query.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.13.intermediate.dense.weight', 'roberta.encoder.layer.18.output.dense.bias', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.17.output.dense.bias', 'roberta.encoder.layer.17.attention.self.value.bias', 'roberta.encoder.layer.22.output.LayerNorm.weight', 'roberta.encoder.layer.21.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.22.attention.self.query.bias', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.21.attention.self.key.weight', 'roberta.encoder.layer.15.output.LayerNorm.weight', 'roberta.encoder.layer.22.attention.self.key.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.16.attention.output.dense.weight', 'roberta.encoder.layer.18.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.23.attention.self.value.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.14.attention.self.key.bias', 'roberta.encoder.layer.19.attention.self.query.weight', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.14.attention.self.value.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.19.attention.output.dense.weight', 'roberta.encoder.layer.19.attention.output.dense.bias', 'roberta.encoder.layer.12.output.dense.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.21.attention.output.LayerNorm.weight', 'roberta.encoder.layer.23.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.21.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.20.intermediate.dense.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.12.attention.self.key.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.15.intermediate.dense.bias', 'roberta.encoder.layer.18.output.dense.weight', 'roberta.encoder.layer.18.attention.self.value.bias', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.14.output.dense.bias', 'roberta.encoder.layer.16.intermediate.dense.weight', 'roberta.encoder.layer.17.intermediate.dense.bias', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.22.attention.output.LayerNorm.weight', 'roberta.encoder.layer.13.attention.self.query.weight', 'roberta.encoder.layer.21.attention.self.query.weight', 'roberta.encoder.layer.20.intermediate.dense.weight', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.12.attention.self.query.weight', 'roberta.encoder.layer.17.attention.self.query.weight', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.20.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.12.attention.self.query.bias', 'roberta.encoder.layer.17.output.LayerNorm.bias', 'roberta.encoder.layer.14.intermediate.dense.weight', 'roberta.encoder.layer.23.output.LayerNorm.bias', 'roberta.encoder.layer.8.intermediate.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at vinai3/bertweet-large/checkpoint-130 and are newly initialized: ['encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.21.attention.self.value.bias', 'pooler.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.14.intermediate.dense.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.16.attention.self.key.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.9.output.dense.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.18.output.LayerNorm.bias', 'pooler.dense.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.20.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.bias', 'classifier.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.22.intermediate.dense.weight', 'classifier.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.10.attention.output.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# specify the path to the saved model\n",
    "model_path = 'vinai3/bertweet-large/checkpoint-130'\n",
    "mymodel = BertForSequenceClassification.from_pretrained(model_path, local_files_only=True, problem_type=\"multi_label_classification\", num_labels=len(labels), id2label=id2label, label2id=label2id)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_label = []\n",
    "tweet_text = []\n",
    "\n",
    "def predict_tweet(x, mymodel):\n",
    "    # encoding = tokenizer(x, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=256)\n",
    "    encoding = tokenizer(x, return_tensors=\"pt\")\n",
    "    encoding = {k: v.to(mymodel.device) for k,v in encoding.items()}\n",
    "    outputs = mymodel(**encoding)\n",
    "    logits = outputs.logits\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(logits.squeeze().cpu())\n",
    "    return labels[probs.argmax()]\n",
    "\n",
    "df_tweets = pd.read_csv(\"sample_tweet_lab0123.csv\")\n",
    "list_tweets = df_tweets[\"text\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:58<00:00,  4.98it/s]\n"
     ]
    }
   ],
   "source": [
    "for x in tqdm.tqdm(list_tweets):\n",
    "    predicted_lab = predict_tweet(x, mymodel)\n",
    "    tweet_label.append(predicted_lab)\n",
    "    tweet_text.append(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_labeled = pd.DataFrame({'tweet_text': tweet_text, 'tweet_label':  tweet_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ignore           277\n",
       "Damages_alert     14\n",
       "Name: tweet_label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_labeled[\"tweet_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  7.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ignore           2\n",
       "Damages_alert    1\n",
       "Name: tweet_label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_label_try = []\n",
    "tweet_text_try = []\n",
    "list_tweets_try = [\"there is a earthquake happening Magnitude 3.4\", \"the ground is shaking\", \"my name is Olivier and happy to follow the Becode Programme #AI\"]\n",
    "for x_try in tqdm.tqdm(list_tweets_try):\n",
    "    predicted_lab_try = predict_tweet(x_try, mymodel)\n",
    "    tweet_label_try.append(predicted_lab_try)\n",
    "    tweet_text_try.append(x_try)\n",
    "df_tweets_labeled_try = pd.DataFrame({'tweet_text': tweet_text_try, 'tweet_label':  tweet_label_try})\n",
    "df_tweets_labeled_try[\"tweet_label\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>there is a earthquake happening Magnitude 3.4</td>\n",
       "      <td>Ignore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the ground is shaking</td>\n",
       "      <td>Damages_alert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my name is Olivier and happy to follow the Bec...</td>\n",
       "      <td>Ignore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text    tweet_label\n",
       "0      there is a earthquake happening Magnitude 3.4         Ignore\n",
       "1                              the ground is shaking  Damages_alert\n",
       "2  my name is Olivier and happy to follow the Bec...         Ignore"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_labeled_try.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code for data engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = pd.read_csv(\"sample_tweet_lab0123.csv\")\n",
    "list_tweets = df_tweets[\"text\"].to_list()\n",
    "model_path = 'mymodel2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for data engineer\n",
    "\n",
    "def predict(list_tweets, model_path) :\n",
    "    labels = ['Ignore', 'Machine_alert', 'Human_alert', 'Damages_alert']\n",
    "    id2label = {0: 'Ignore', 1: 'Machine_alert', 2: 'Human_alert', 3: 'Damages_alert'}\n",
    "    label2id = {'Ignore': 0, 'Machine_alert': 1, 'Human_alert': 2, 'Damages_alert': 3}\n",
    "    model_path = 'bert-finetuned-sem_eval-english/checkpoint-170'\n",
    "    mymodel = BertForSequenceClassification.from_pretrained(model_path, local_files_only=True, problem_type=\"multi_label_classification\", num_labels=len(labels), id2label=id2label, label2id=label2id)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-large\")\n",
    "    tweet_label = []\n",
    "    tweet_text = []\n",
    "\n",
    "    def predict_tweet(x, mymodel):\n",
    "        encoding = tokenizer(x, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=128)\n",
    "        encoding = {k: v.to(mymodel.device) for k,v in encoding.items()}\n",
    "        outputs = mymodel(**encoding)\n",
    "        logits = outputs.logits\n",
    "        sigmoid = torch.nn.Sigmoid()\n",
    "        probs = sigmoid(logits.squeeze().cpu())\n",
    "        return labels[probs.argmax()]\n",
    "    \n",
    "    for x in (list_tweets):\n",
    "        predicted_lab = predict_tweet(x, mymodel)\n",
    "        tweet_label.append(predicted_lab)\n",
    "        tweet_text.append(x)\n",
    "    df_tweets_labeled = pd.DataFrame({'tweet_text': tweet_text, 'tweet_label':  tweet_label})\n",
    "    return df_tweets_labeled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at mymodel2 were not used when initializing BertForSequenceClassification: ['roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.19.output.LayerNorm.weight', 'roberta.encoder.layer.20.attention.self.value.bias', 'roberta.encoder.layer.22.attention.self.query.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.12.output.LayerNorm.weight', 'roberta.encoder.layer.23.intermediate.dense.weight', 'roberta.encoder.layer.18.attention.output.LayerNorm.weight', 'roberta.encoder.layer.23.attention.self.key.bias', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.19.output.dense.weight', 'roberta.encoder.layer.14.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.19.attention.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.self.value.bias', 'roberta.encoder.layer.1.attention.self.query.weight', 'classifier.dense.weight', 'roberta.encoder.layer.22.attention.self.key.bias', 'roberta.encoder.layer.22.attention.output.dense.weight', 'roberta.encoder.layer.14.attention.output.LayerNorm.weight', 'roberta.encoder.layer.15.attention.self.value.weight', 'roberta.encoder.layer.17.attention.output.dense.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.21.attention.self.query.bias', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.17.attention.output.dense.weight', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.17.attention.self.key.bias', 'roberta.encoder.layer.14.attention.self.key.weight', 'roberta.encoder.layer.16.attention.self.value.weight', 'roberta.encoder.layer.15.attention.output.LayerNorm.weight', 'roberta.encoder.layer.17.output.LayerNorm.weight', 'roberta.encoder.layer.19.attention.self.key.weight', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.13.attention.self.value.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.14.attention.self.value.bias', 'roberta.encoder.layer.19.attention.self.value.weight', 'roberta.encoder.layer.16.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.15.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.18.intermediate.dense.bias', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.23.attention.output.dense.weight', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.14.attention.output.dense.weight', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.18.attention.output.dense.weight', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.12.attention.output.dense.bias', 'roberta.encoder.layer.15.output.dense.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.21.attention.output.LayerNorm.bias', 'roberta.encoder.layer.16.attention.self.value.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.14.output.LayerNorm.weight', 'roberta.encoder.layer.16.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.22.attention.output.dense.bias', 'roberta.encoder.layer.23.attention.output.LayerNorm.bias', 'roberta.encoder.layer.18.attention.self.query.weight', 'roberta.encoder.layer.23.attention.self.query.weight', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.18.intermediate.dense.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.23.attention.output.dense.bias', 'roberta.encoder.layer.14.output.dense.weight', 'roberta.encoder.layer.13.attention.output.LayerNorm.weight', 'roberta.encoder.layer.20.attention.self.value.weight', 'roberta.encoder.layer.22.attention.self.value.weight', 'roberta.encoder.layer.16.attention.self.query.weight', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.20.attention.self.key.bias', 'roberta.encoder.layer.13.output.dense.weight', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.12.attention.self.value.weight', 'roberta.encoder.layer.14.attention.output.dense.bias', 'classifier.out_proj.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.12.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.15.attention.output.dense.bias', 'roberta.encoder.layer.18.attention.output.dense.bias', 'roberta.encoder.layer.18.attention.self.key.weight', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.16.intermediate.dense.bias', 'roberta.encoder.layer.15.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.15.attention.self.key.bias', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.15.attention.self.value.bias', 'roberta.encoder.layer.21.attention.self.value.weight', 'classifier.dense.bias', 'roberta.encoder.layer.16.attention.self.query.bias', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.23.output.dense.bias', 'roberta.encoder.layer.19.intermediate.dense.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.13.attention.self.value.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.21.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.23.intermediate.dense.bias', 'roberta.encoder.layer.16.attention.output.dense.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.19.attention.self.key.bias', 'roberta.encoder.layer.20.output.dense.bias', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.12.attention.self.value.bias', 'roberta.encoder.layer.22.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.20.attention.output.dense.weight', 'roberta.encoder.layer.16.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.20.attention.self.key.weight', 'roberta.encoder.layer.17.attention.output.LayerNorm.bias', 'roberta.encoder.layer.16.attention.self.key.bias', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.13.attention.output.dense.bias', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.17.attention.self.key.weight', 'roberta.encoder.layer.12.attention.output.LayerNorm.weight', 'roberta.encoder.layer.18.attention.self.value.weight', 'roberta.encoder.layer.13.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.23.attention.self.key.weight', 'roberta.encoder.layer.21.attention.output.dense.bias', 'roberta.encoder.layer.12.attention.self.key.bias', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.12.intermediate.dense.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.13.attention.self.key.bias', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.22.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.12.attention.output.dense.weight', 'roberta.encoder.layer.13.attention.output.dense.weight', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.23.attention.self.value.weight', 'roberta.encoder.layer.16.output.dense.bias', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.20.attention.self.query.bias', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.12.intermediate.dense.weight', 'roberta.encoder.layer.17.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.19.output.LayerNorm.bias', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.20.output.dense.weight', 'roberta.encoder.layer.22.attention.self.value.bias', 'roberta.encoder.layer.21.output.LayerNorm.weight', 'roberta.encoder.layer.13.output.LayerNorm.bias', 'roberta.encoder.layer.15.attention.self.key.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.20.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.12.output.dense.weight', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.16.output.dense.weight', 'roberta.encoder.layer.15.attention.self.query.bias', 'roberta.encoder.layer.19.attention.self.query.bias', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.22.output.dense.bias', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.15.output.dense.bias', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.17.intermediate.dense.weight', 'roberta.encoder.layer.15.attention.self.query.weight', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.19.output.dense.bias', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.19.intermediate.dense.weight', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.13.intermediate.dense.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.18.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.20.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.21.output.dense.weight', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.23.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.20.output.LayerNorm.weight', 'roberta.encoder.layer.17.output.dense.weight', 'roberta.encoder.layer.23.attention.self.query.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.18.attention.output.LayerNorm.bias', 'roberta.encoder.layer.16.output.LayerNorm.bias', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.13.output.dense.bias', 'roberta.encoder.layer.15.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.19.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.16.attention.self.key.weight', 'roberta.encoder.layer.20.attention.self.query.weight', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.13.output.LayerNorm.weight', 'roberta.encoder.layer.14.output.LayerNorm.bias', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.21.attention.self.value.bias', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.15.output.LayerNorm.bias', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.21.attention.self.key.bias', 'roberta.encoder.layer.21.output.dense.bias', 'roberta.encoder.layer.18.attention.self.key.bias', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.14.attention.self.query.bias', 'roberta.encoder.layer.17.attention.self.query.bias', 'roberta.encoder.layer.21.intermediate.dense.bias', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.22.output.dense.weight', 'roberta.encoder.layer.22.intermediate.dense.weight', 'roberta.encoder.layer.13.attention.self.query.bias', 'roberta.encoder.layer.17.attention.self.value.weight', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.20.output.LayerNorm.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.23.output.dense.weight', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.22.intermediate.dense.bias', 'roberta.encoder.layer.14.intermediate.dense.bias', 'roberta.encoder.layer.13.attention.self.key.weight', 'roberta.encoder.layer.14.attention.self.query.weight', 'classifier.out_proj.bias', 'roberta.encoder.layer.12.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.embeddings.position_ids', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.18.attention.self.query.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.13.intermediate.dense.weight', 'roberta.encoder.layer.18.output.dense.bias', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.17.output.dense.bias', 'roberta.encoder.layer.17.attention.self.value.bias', 'roberta.encoder.layer.22.output.LayerNorm.weight', 'roberta.encoder.layer.21.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.22.attention.self.query.bias', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.21.attention.self.key.weight', 'roberta.encoder.layer.15.output.LayerNorm.weight', 'roberta.encoder.layer.22.attention.self.key.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.16.attention.output.dense.weight', 'roberta.encoder.layer.18.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.23.attention.self.value.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.14.attention.self.key.bias', 'roberta.encoder.layer.19.attention.self.query.weight', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.14.attention.self.value.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.19.attention.output.dense.weight', 'roberta.encoder.layer.19.attention.output.dense.bias', 'roberta.encoder.layer.12.output.dense.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.21.attention.output.LayerNorm.weight', 'roberta.encoder.layer.23.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.21.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.20.intermediate.dense.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.12.attention.self.key.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.15.intermediate.dense.bias', 'roberta.encoder.layer.18.output.dense.weight', 'roberta.encoder.layer.18.attention.self.value.bias', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.14.output.dense.bias', 'roberta.encoder.layer.16.intermediate.dense.weight', 'roberta.encoder.layer.17.intermediate.dense.bias', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.22.attention.output.LayerNorm.weight', 'roberta.encoder.layer.13.attention.self.query.weight', 'roberta.encoder.layer.21.attention.self.query.weight', 'roberta.encoder.layer.20.intermediate.dense.weight', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.12.attention.self.query.weight', 'roberta.encoder.layer.17.attention.self.query.weight', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.20.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.12.attention.self.query.bias', 'roberta.encoder.layer.17.output.LayerNorm.bias', 'roberta.encoder.layer.14.intermediate.dense.weight', 'roberta.encoder.layer.23.output.LayerNorm.bias', 'roberta.encoder.layer.8.intermediate.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at mymodel2 and are newly initialized: ['encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.13.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.21.attention.self.value.bias', 'pooler.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.14.intermediate.dense.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.16.attention.self.key.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.9.output.dense.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.18.output.LayerNorm.bias', 'pooler.dense.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.14.output.dense.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.20.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.21.output.dense.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.22.output.dense.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.16.output.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.bias', 'classifier.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.22.intermediate.dense.weight', 'classifier.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.10.attention.output.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#Code 2 for data engineers\n",
    "\n",
    "labels = ['Ignore', 'Machine_alert', 'Human_alert', 'Damages_alert']\n",
    "id2label = {0: 'Ignore', 1: 'Machine_alert', 2: 'Human_alert', 3: 'Damages_alert'}\n",
    "label2id = {'Ignore': 0, 'Machine_alert': 1, 'Human_alert': 2, 'Damages_alert': 3}\n",
    "model_path = 'mymodel2'\n",
    "mymodel = BertForSequenceClassification.from_pretrained(model_path, local_files_only=True, problem_type=\"multi_label_classification\", num_labels=len(labels), id2label=id2label, label2id=label2id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-large\")\n",
    "\n",
    "def predict_tweet(x, mymodel):\n",
    "    encoding = tokenizer(x, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=128)\n",
    "    encoding = {k: v.to(mymodel.device) for k,v in encoding.items()}\n",
    "    outputs = mymodel(**encoding)\n",
    "    logits = outputs.logits\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(logits.squeeze().cpu())\n",
    "    label = labels[probs.argmax()]\n",
    "    dic_tweet_label = {x:label}\n",
    "    return dic_tweet_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoded_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m encoded_dataset\u001b[39m.\u001b[39mset_format(\u001b[39m\"\u001b[39m\u001b[39mtorch\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'encoded_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "encoded_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A message from the Queen to the people of  # Mexico following the resent earthquake . '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = list_tweets[0]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A message from the Queen to the people of  # Mexico following the resent earthquake . ': 'Human_alert'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_tweet(x, mymodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at mymodel2 were not used when initializing BertForSequenceClassification: ['roberta.encoder.layer.13.attention.output.LayerNorm.weight', 'roberta.encoder.layer.16.attention.self.query.bias', 'roberta.encoder.layer.19.attention.output.LayerNorm.weight', 'roberta.encoder.layer.22.attention.self.value.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.14.output.dense.weight', 'roberta.encoder.layer.13.intermediate.dense.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.14.output.dense.bias', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.12.attention.self.query.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.16.intermediate.dense.bias', 'roberta.encoder.layer.14.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.21.attention.self.value.weight', 'roberta.encoder.layer.23.output.dense.bias', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.19.attention.self.value.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.20.attention.output.dense.weight', 'roberta.encoder.layer.14.attention.self.query.bias', 'roberta.encoder.layer.18.intermediate.dense.bias', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.20.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.18.output.LayerNorm.bias', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.19.attention.output.LayerNorm.bias', 'roberta.encoder.layer.14.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.self.key.weight', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.12.attention.self.query.weight', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.20.attention.self.query.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.16.attention.output.dense.bias', 'roberta.encoder.layer.16.attention.self.value.bias', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.16.attention.output.dense.weight', 'roberta.encoder.layer.21.attention.self.value.bias', 'roberta.encoder.layer.15.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.19.output.LayerNorm.bias', 'roberta.encoder.layer.22.output.dense.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.12.intermediate.dense.bias', 'classifier.out_proj.weight', 'roberta.encoder.layer.23.attention.self.key.weight', 'roberta.encoder.layer.15.attention.output.dense.weight', 'roberta.encoder.layer.22.attention.self.value.bias', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.13.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.15.intermediate.dense.bias', 'roberta.encoder.layer.19.intermediate.dense.weight', 'roberta.encoder.layer.17.output.LayerNorm.bias', 'roberta.encoder.layer.13.attention.self.query.bias', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.14.attention.self.key.weight', 'roberta.encoder.layer.16.attention.self.query.weight', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.14.attention.self.value.bias', 'roberta.encoder.layer.13.attention.self.query.weight', 'roberta.encoder.layer.16.intermediate.dense.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.22.attention.output.LayerNorm.weight', 'roberta.encoder.layer.21.output.LayerNorm.weight', 'roberta.encoder.layer.17.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.23.attention.output.dense.bias', 'roberta.encoder.layer.12.attention.self.key.bias', 'roberta.encoder.layer.17.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.15.output.dense.bias', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.22.attention.output.dense.bias', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.13.attention.self.key.bias', 'roberta.encoder.layer.22.attention.self.key.weight', 'roberta.encoder.layer.17.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.15.attention.self.key.weight', 'roberta.encoder.layer.16.output.LayerNorm.bias', 'roberta.encoder.layer.23.attention.self.value.bias', 'roberta.encoder.layer.23.intermediate.dense.bias', 'roberta.encoder.layer.14.attention.self.value.weight', 'classifier.out_proj.bias', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.22.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.18.output.dense.weight', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.15.output.LayerNorm.bias', 'roberta.encoder.layer.18.attention.self.query.bias', 'roberta.embeddings.position_ids', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.12.output.dense.weight', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.21.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.16.output.dense.bias', 'roberta.encoder.layer.17.output.dense.weight', 'roberta.encoder.layer.20.attention.self.key.bias', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.21.attention.output.dense.weight', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.15.attention.self.value.bias', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.21.attention.output.LayerNorm.weight', 'roberta.encoder.layer.15.attention.output.dense.bias', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.22.attention.output.dense.weight', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.12.attention.output.dense.bias', 'roberta.encoder.layer.20.attention.self.value.bias', 'roberta.encoder.layer.22.output.LayerNorm.weight', 'roberta.encoder.layer.13.output.dense.bias', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.22.attention.self.query.weight', 'roberta.encoder.layer.14.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.22.intermediate.dense.bias', 'roberta.encoder.layer.23.attention.self.value.weight', 'roberta.encoder.layer.21.output.dense.weight', 'roberta.encoder.layer.13.output.LayerNorm.bias', 'roberta.encoder.layer.21.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.self.query.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.14.intermediate.dense.bias', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.13.attention.self.key.weight', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.20.attention.self.query.bias', 'roberta.encoder.layer.19.output.dense.bias', 'roberta.encoder.layer.12.attention.self.key.weight', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.19.attention.self.value.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.23.output.dense.weight', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.16.attention.self.key.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.21.attention.self.query.bias', 'roberta.encoder.layer.14.intermediate.dense.weight', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.22.attention.self.query.bias', 'roberta.encoder.layer.14.attention.output.LayerNorm.weight', 'roberta.encoder.layer.20.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.18.attention.self.key.weight', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.18.attention.output.LayerNorm.bias', 'roberta.encoder.layer.12.output.LayerNorm.weight', 'roberta.encoder.layer.16.attention.self.key.bias', 'roberta.encoder.layer.17.attention.self.query.weight', 'roberta.encoder.layer.19.attention.self.query.bias', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.22.attention.self.key.bias', 'roberta.encoder.layer.14.output.LayerNorm.weight', 'roberta.encoder.layer.21.attention.self.query.weight', 'roberta.encoder.layer.18.attention.output.dense.weight', 'classifier.dense.bias', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.12.intermediate.dense.weight', 'roberta.encoder.layer.13.attention.self.value.bias', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.15.intermediate.dense.weight', 'roberta.encoder.layer.18.attention.output.dense.bias', 'roberta.encoder.layer.12.attention.output.LayerNorm.bias', 'roberta.encoder.layer.16.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.12.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.18.attention.output.LayerNorm.weight', 'roberta.encoder.layer.19.attention.self.key.bias', 'roberta.encoder.layer.14.attention.self.key.bias', 'roberta.encoder.layer.23.intermediate.dense.weight', 'roberta.encoder.layer.12.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.19.output.dense.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.18.attention.self.query.weight', 'roberta.encoder.layer.12.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.21.intermediate.dense.weight', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.16.attention.self.value.weight', 'classifier.dense.weight', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.16.attention.output.LayerNorm.weight', 'roberta.encoder.layer.23.attention.output.dense.weight', 'roberta.encoder.layer.17.attention.self.value.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.13.intermediate.dense.weight', 'roberta.encoder.layer.19.attention.output.dense.bias', 'roberta.encoder.layer.17.attention.self.value.bias', 'roberta.encoder.layer.17.attention.self.key.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.23.attention.output.LayerNorm.weight', 'roberta.encoder.layer.18.output.dense.bias', 'roberta.encoder.layer.20.attention.output.dense.bias', 'roberta.encoder.layer.15.attention.self.key.bias', 'roberta.encoder.layer.23.attention.self.query.weight', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.12.attention.self.value.bias', 'roberta.encoder.layer.19.intermediate.dense.bias', 'roberta.encoder.layer.14.attention.output.dense.bias', 'roberta.encoder.layer.20.intermediate.dense.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.20.output.dense.weight', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.22.output.dense.weight', 'roberta.encoder.layer.15.attention.output.LayerNorm.weight', 'roberta.encoder.layer.21.attention.self.key.weight', 'roberta.encoder.layer.15.output.dense.weight', 'roberta.encoder.layer.22.output.LayerNorm.bias', 'roberta.encoder.layer.21.attention.self.key.bias', 'roberta.encoder.layer.14.attention.self.query.weight', 'roberta.encoder.layer.17.intermediate.dense.weight', 'roberta.encoder.layer.12.output.dense.bias', 'roberta.encoder.layer.20.attention.self.key.weight', 'roberta.encoder.layer.13.attention.self.value.weight', 'roberta.encoder.layer.19.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.12.attention.self.value.weight', 'roberta.encoder.layer.23.output.LayerNorm.bias', 'roberta.encoder.layer.23.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.15.attention.self.query.bias', 'roberta.encoder.layer.20.attention.self.value.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.23.attention.self.query.bias', 'roberta.encoder.layer.18.attention.self.value.bias', 'roberta.encoder.layer.13.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.20.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.15.output.LayerNorm.weight', 'roberta.encoder.layer.17.output.dense.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.21.intermediate.dense.bias', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.17.attention.self.query.bias', 'roberta.encoder.layer.21.output.dense.bias', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.18.attention.self.key.bias', 'roberta.encoder.layer.13.output.dense.weight', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.17.attention.self.key.weight', 'roberta.encoder.layer.22.intermediate.dense.weight', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.21.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.18.intermediate.dense.weight', 'roberta.encoder.layer.19.attention.output.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.16.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.17.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.23.attention.self.key.bias', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.13.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.16.output.dense.weight', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.23.output.LayerNorm.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.20.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.13.attention.output.dense.weight', 'roberta.encoder.layer.17.attention.output.dense.weight', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.18.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.20.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.15.attention.self.query.weight', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.20.output.dense.bias', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.15.attention.self.value.weight', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.18.attention.self.value.weight', 'roberta.encoder.layer.17.intermediate.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at mymodel2 and are newly initialized: ['encoder.layer.0.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.14.output.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.20.attention.self.key.weight', 'pooler.dense.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.20.output.dense.bias', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.19.output.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.18.intermediate.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'classifier.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.16.output.dense.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.17.output.dense.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.16.attention.self.key.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'classifier.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.19.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.key.weight', 'pooler.dense.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.13.output.dense.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.18.output.dense.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.14.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A message from the Queen to the people of  # M...</td>\n",
       "      <td>Human_alert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As we r commemorating the 1906 quake today, we...</td>\n",
       "      <td>Human_alert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xavier is crowdrising for Relief support for E...</td>\n",
       "      <td>Human_alert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thinking of our friends around Kaikoura and ot...</td>\n",
       "      <td>Human_alert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT  @ abpnewstv :   # EcuadorEarthquake :  At ...</td>\n",
       "      <td>Human_alert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Ive been awake all night with these bloody aft...</td>\n",
       "      <td>Human_alert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>Some clown was letting off fireworks last nigh...</td>\n",
       "      <td>Human_alert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>Took a tour of Quito Ecuador after the earthqu...</td>\n",
       "      <td>Human_alert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>RT  @ thesecondascent :  7 . 4 magnitude earth...</td>\n",
       "      <td>Human_alert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>RT  @ humanityfirstuk :  Already 6 aftershocks...</td>\n",
       "      <td>Machine_alert</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>291 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            tweet_text    tweet_label\n",
       "0    A message from the Queen to the people of  # M...    Human_alert\n",
       "1    As we r commemorating the 1906 quake today, we...    Human_alert\n",
       "2    Xavier is crowdrising for Relief support for E...    Human_alert\n",
       "3    Thinking of our friends around Kaikoura and ot...    Human_alert\n",
       "4    RT  @ abpnewstv :   # EcuadorEarthquake :  At ...    Human_alert\n",
       "..                                                 ...            ...\n",
       "286  Ive been awake all night with these bloody aft...    Human_alert\n",
       "287  Some clown was letting off fireworks last nigh...    Human_alert\n",
       "288  Took a tour of Quito Ecuador after the earthqu...    Human_alert\n",
       "289  RT  @ thesecondascent :  7 . 4 magnitude earth...    Human_alert\n",
       "290  RT  @ humanityfirstuk :  Already 6 aftershocks...  Machine_alert\n",
       "\n",
       "[291 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(list_tweets, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
